heizoel = 5
)  -> data_renamed
print("date renamed")
print(head(data_renamed))
# remove empty columns ----------------------------------------------------
data_only_necessary_cols = data_renamed %>%
select(
-c(6,7,8)
)
print("data only necessary cols")
print(head(data_only_necessary_cols))
data_only_necessary_cols %>%
filter(
if_all(
everything(),
~!is.na(.x)
)
) -> data_no_na
print("data only no na")
print(head(data_no_na))
data_no_na %>%
split(.$country) %>%
lapply(function(x) {
x = x[2:nrow(x),]
# format date and numeric types
x[["date"]] = as.Date(as.numeric(x$date), origin = as.Date("1899-12-30"))
x = x %>% mutate(across(2:ncol(.),
~ gsub(",", "", .x)))
# filter only after 2020
x = x %>%
filter(
date > as.Date("2020-01-01")
)
}) %>% bind_rows() %>%
mutate(
country = recode(country,
"AT"  = "Österreich",
"BG" = "Bulgarien",
"BE"  = "Belgien",
"BU"  = "Bulgarien",
"CY"  = "Zypern",
"CZ"  = "Tschechien",
"DE"  = "Deutschland",
"DK"  = "Dänemark",
"EE"  = "Estland",
"ES"  = "Spanien",
"FI"  = "Finnland",
"FR"  = "Frankreich",
"GR"  = "Griechenland",
"HU"  = "Ungarn",
"LV"  = "Lettland",
"IT"  = "Italien",
"RO"  = "Rumänien",
"LT"  = "Lituaen",
"PT"  = "Portugal",
"HR" = "Kroatien",
"IE" = "Irland",
"LU" = "Luxemburg",
"SE"  = "Schweden",
"SI"  = "Slovenien",
"SK"  = "Slovakei",
"PL"  = "Polen",
"EE"  = "Estland",
"MT" = "Malta",
"NL" = "Niederlanden"
)
) -> one_df_all_countries
print("formatted data")
print(head(one_df_all_countries))
# only take the diesel ----------------------------------------------------
one_df_all_countries %>%
select(
1,
country,
diesel
) %>%
mutate(
diesel = as.numeric(diesel) / 1000
) %>%
pivot_wider(
names_from = country,
values_from = diesel
) -> diesel_wide
diesel_wide
path_diesel = here::here("R/output/weekly_fuel_prices/historic/historic_diesel.csv")
dir = dirname(path_diesel); if(!dir.exists(dir)) dir.create(dir, recursive = T)
write.csv(diesel_wide, path_diesel)
library(httr)
# 2.12
url = "https://www.bruegel.org/sites/default/files/2022-11/Gas%20tracker%2029.11.22.zip"
# download zip ------------------------------------------------------------
download_path = tempfile()
download_dir = dirname(download_path)
# Download the data in loop -----------------------------------------------
success = FALSE
i = 1
while(!success & i <= 5) {
print(paste0("Try for the ", i, ". time"))
# try the download
res = httr::GET(url, write_disk(download_path, overwrite = T))
print(paste0("res: ", res$status_code))
# if it did work
if (res$status_code == 200) {
success = TRUE
}
# if it did not work
i = i + 1
}
if(!res$status_code == 200) stop("Download did not work after 5 tries")
unzip(download_path, exdir = download_dir)
# the unzipped file does not contain the files, but another directory which apparently
# changes each week its name. But every week so far the word "Gas" was in it
unzipped_dir_name = dir(download_dir, ".*[gG]as.*", full.names = T)
# find file
files = dir(unzipped_dir_name, "*.csv|xlsx", full.names = T)
print(paste0("files: ", files))
file_idx = which(grepl("country_data", files))
# read data
data = read.csv(files[[file_idx]])
# wrangle it a bit
col_indices = which(grepl("week|Russia_", names(data)))
data = data[, col_indices]
data[["EU Ziel"]] = (1/3) * data$Russia_2021
print(head(data))
print(tail(data))
names(data)[names(data) == "Russia_avg"] = "Durchschnitt 2015 - 2022"
data
# remove comma ------------------------------------------------------------
data %>%
mutate(
across(where(is.numeric),
~as.numeric(gsub(",", "", .x))
)
)
data
# remove comma ------------------------------------------------------------
data %>%
mutate(
across(where(is.numeric),
~as.numeric(gsub(",", "", .x))
)
)
data %>% glimpse
# remove comma ------------------------------------------------------------
data %>%
mutate(
across(where(is.charcter),
~as.numeric(gsub(",", "", .x))
)
)
# remove comma ------------------------------------------------------------
data %>%
mutate(
across(where(is.character),
~as.numeric(gsub(",", "", .x))
)
)
# remove comma ------------------------------------------------------------
data %>%
mutate(
across(where(is.character),
~as.numeric(gsub(",", "", .x))
)
) -> data
output_file = "R/output/natural_gas_russia_europe.csv"
dir = dirname(output_file); if(!dir.exists(dir)) dir.create(dir, recursive = T)
write.csv(data, output_file)
library(httr)
# 2.12
url = "https://www.bruegel.org/sites/default/files/2022-11/Gas%20tracker%2029.11.22.zip"
# 9.12
url = "https://www.bruegel.org/sites/default/files/2022-12/Gas%20tracker%2007.12.22.zip"
# download zip ------------------------------------------------------------
download_path = tempfile()
download_dir = dirname(download_path)
# Download the data in loop -----------------------------------------------
success = FALSE
i = 1
while(!success & i <= 5) {
print(paste0("Try for the ", i, ". time"))
# try the download
res = httr::GET(url, write_disk(download_path, overwrite = T))
print(paste0("res: ", res$status_code))
# if it did work
if (res$status_code == 200) {
success = TRUE
}
# if it did not work
i = i + 1
}
if(!res$status_code == 200) stop("Download did not work after 5 tries")
unzip(download_path, exdir = download_dir)
# the unzipped file does not contain the files, but another directory which apparently
# changes each week its name. But every week so far the word "Gas" was in it
unzipped_dir_name = dir(download_dir, ".*[gG]as.*", full.names = T)
# find file
files = dir(unzipped_dir_name, "*.csv|xlsx", full.names = T)
print(paste0("files: ", files))
file_idx = which(grepl("country_data", files))
# read data
data = read.csv(files[[file_idx]])
# wrangle it a bit
col_indices = which(grepl("week|Russia_", names(data)))
data = data[, col_indices]
data[["EU Ziel"]] = (1/3) * data$Russia_2021
print(head(data))
print(tail(data))
names(data)[names(data) == "Russia_avg"] = "Durchschnitt 2015 - 2022"
names(data)[names(data) == "Russia_2022"] = "2022"
# remove comma ------------------------------------------------------------
data %>%
mutate(
across(where(is.character),
~as.numeric(gsub(",", "", .x))
)
) -> data
library(tidyverse)
# remove comma ------------------------------------------------------------
data %>%
mutate(
across(where(is.character),
~as.numeric(gsub(",", "", .x))
)
) -> data
output_file = "R/output/natural_gas_russia_europe.csv"
dir = dirname(output_file); if(!dir.exists(dir)) dir.create(dir, recursive = T)
write.csv(data, output_file)
install.packages("rlist")
library(rlist)
devs <-
list(
p1=list(name="Ken",age=24,
interest=c("reading","music","movies"),
lang=list(r=2,csharp=4)),
p2=list(name="James",age=25,
interest=c("sports","music"),
lang=list(r=3,java=2,cpp=5)),
p3=list(name="Penny",age=24,
interest=c("movies","reading"),
lang=list(r=1,cpp=4,python=2)))
devs
str(devs)
glimpse(devs)
library(tidyverse)
glimpse(devs)
library(rlist)
rlist::list.filter(devs, "music" %in% interest)
install.packages("terse")
devtools::install_github("coolbutuseless/terse")
library(rvest)
html = rvest::read_html("https://www.bruegel.org/dataset/european-natural-gas-imports")
html
html %>%
html_elements('a[title="Download data"]')
html %>%
html_elements('a[title="Download data"]') %>%
html_attr("href")
library(rvest)
# find the link
html_attribute("href", html_elements(html, 'a[title="Download data"]'))
# find the link
html_attr("href", html_elements(html, 'a[title="Download data"]'))
html_elements(html, 'a[title="Download data"]')
?html_attr
# find the link
html_attr(html_elements(html, 'a[title="Download data"]'), "href")
# find the link
path = html_attr(html_elements(html, 'a[title="Download data"]'), "href")
paste0("https://www.bruegel.org/", path)
# read the html
html = rvest::read_html("https://www.bruegel.org/dataset/european-natural-gas-imports")
# find the link
path = html_attr(html_elements(html, 'a[title="Download data"]'), "href")
url = paste0("https://www.bruegel.org/", path)
url
# download zip ------------------------------------------------------------
download_path = tempfile()
download_dir = dirname(download_path)
# Download the data in loop -----------------------------------------------
success = FALSE
i = 1
while(!success & i <= 5) {
print(paste0("Try for the ", i, ". time"))
# try the download
res = httr::GET(url, write_disk(download_path, overwrite = T))
print(paste0("res: ", res$status_code))
# if it did work
if (res$status_code == 200) {
success = TRUE
}
# if it did not work
i = i + 1
}
library(httr)
library(rvest)
# Download the data in loop -----------------------------------------------
success = FALSE
i = 1
while(!success & i <= 5) {
print(paste0("Try for the ", i, ". time"))
# try the download
res = httr::GET(url, write_disk(download_path, overwrite = T))
print(paste0("res: ", res$status_code))
# if it did work
if (res$status_code == 200) {
success = TRUE
}
# if it did not work
i = i + 1
}
if(!res$status_code == 200) stop("Download did not work after 5 tries")
unzip(download_path, exdir = download_dir)
# the unzipped file does not contain the files, but another directory which apparently
# changes each week its name. But every week so far the word "Gas" was in it
unzipped_dir_name = dir(download_dir, ".*[gG]as.*", full.names = T)
# find file
files = dir(unzipped_dir_name, "*.csv|xlsx", full.names = T)
print(paste0("files: ", files))
file_idx = which(grepl("country_data", files))
# read data
data = read.csv(files[[file_idx]])
# wrangle it a bit
col_indices = which(grepl("week|Russia_", names(data)))
data = data[, col_indices]
data[["EU Ziel"]] = (1/3) * data$Russia_2021
# find file
files = dir(unzipped_dir_name, "*.csv|xlsx", full.names = T)
print(paste0("files: ", files))
file_idx = which(grepl("country_data", files))
# read data
data = read.csv(files[[file_idx]])
data
View(data)
# wrangle it a bit
col_indices = which(grepl("week|Russia_", names(data)))
data = data[, col_indices]
data[["EU Ziel"]] = (1/3) * data$Russia_2021
data$Russia_2021 * 1/3
data$Russia_2021
data %>% glimpse
str(data)
# format as numeric
lapply(data, as.numeric)
# 15.12
url = "https://www.bruegel.org/sites/default/files/2022-12/Gas%20tracker%2013.12.22.zip"
# download zip ------------------------------------------------------------
download_path = tempfile()
download_dir = dirname(download_path)
# Download the data in loop -----------------------------------------------
success = FALSE
i = 1
while(!success & i <= 5) {
print(paste0("Try for the ", i, ". time"))
# try the download
res = httr::GET(url, write_disk(download_path, overwrite = T))
print(paste0("res: ", res$status_code))
# if it did work
if (res$status_code == 200) {
success = TRUE
}
# if it did not work
i = i + 1
}
if(!res$status_code == 200) stop("Download did not work after 5 tries")
unzip(download_path, exdir = download_dir)
# the unzipped file does not contain the files, but another directory which apparently
# changes each week its name. But every week so far the word "Gas" was in it
unzipped_dir_name = dir(download_dir, ".*[gG]as.*", full.names = T)
# find file
files = dir(unzipped_dir_name, "*.csv|xlsx", full.names = T)
print(paste0("files: ", files))
file_idx = which(grepl("country_data", files))
# read data
data = read.csv(files[[file_idx]])
data
str(data)
data
str(data)
library(dplyr)
data %>%
mutate(
across(where(is.character),
~as.numeric(gsub(",", "", .x))
)
) -> data
data
data %>% glimpse()
# wrangle it a bit
col_indices = which(grepl("week|Russia_", names(data)))
data = data[, col_indices]
daa
data
data[["EU Ziel"]] = (1/3) * data$Russia_2021
View(data)
library(rvest)
library(dplyr)
# url ---------------------------------------------------------------------
url = "https://www.bruegel.org/dataset/european-natural-gas-demand-tracker"
# get the table -----------------------------------------------------------
rvest::read_html(url) %>%
html_elements("table")
# url ---------------------------------------------------------------------
url = "https://www.bruegel.org/dataset/european-natural-gas-demand-tracker"
# get the table -----------------------------------------------------------
rvest::read_html(url) %>%
html_elements("table")
# get the table -----------------------------------------------------------
rvest::read_html(url)
library(httr)
jk
library(rvest)
library(dplyr)
# 15.12
url = "https://www.bruegel.org/sites/default/files/2022-12/Gas%20tracker%2013.12.22.zip"
# read the html
html = rvest::read_html("https://www.bruegel.org/dataset/european-natural-gas-imports")
# find the link
path = html_attr(html_elements(html, 'a[title="Download data"]'), "href")
path
url = paste0("https://www.bruegel.org/", path)
url
# download zip ------------------------------------------------------------
download_path = tempfile()
download_dir = dirname(download_path)
# Download the data in loop -----------------------------------------------
success = FALSE
i = 1
while(!success & i <= 5) {
print(paste0("Try for the ", i, ". time"))
# try the download
res = httr::GET(url, write_disk(download_path, overwrite = T))
print(paste0("res: ", res$status_code))
# if it did work
if (res$status_code == 200) {
success = TRUE
}
# if it did not work
i = i + 1
}
if(!res$status_code == 200) stop("Download did not work after 5 tries")
unzip(download_path, exdir = download_dir)
# the unzipped file does not contain the files, but another directory which apparently
# changes each week its name. But every week so far the word "Gas" was in it
unzipped_dir_name = dir(download_dir, ".*[gG]as.*", full.names = T)
# find file
files = dir(unzipped_dir_name, "*.csv|xlsx", full.names = T)
print(paste0("files: ", files))
file_idx = which(grepl("country_data", files))
# read data
data = read.csv(files[[file_idx]])
# find file
files = dir(unzipped_dir_name, "*.csv|xlsx", full.names = T)
print(paste0("files: ", files))
file_idx = which(grepl("country_data", files))
file_idx
files
# read data
data = read.csv(files[[file_idx]])
# read data
data = read.csv(files[[file_idx]])
read_csv(files[[2]])
library(tidyverse)
read_csv(files[[2]])
files
url = paste0("https://www.bruegel.org/", path)
url
# the unzipped file does not contain the files, but another directory which apparently
# changes each week its name. But every week so far the word "Gas" was in it
unzipped_dir_name = dir(download_dir, ".*[gG]as.*", full.names = T)
unzipped_dir_name
# find file
files = dir(unzipped_dir_name, "*.csv|xlsx", full.names = T)
files
print(paste0("files: ", files))
file_idx = which(grepl("country_data", files))
file_idx = which(grepl("country_data", files))
file_idx
# find the file -----------------------------------------------------------
file = files[[file_idx]]
file
basename(file)
strsplit(basename(file), "\\.")
strsplit(basename(file), "\\.") %>% .[[1]]
strsplit(basename(file), "\\.") %>% .[[1]] %>% .[[2]]
fileEnding = strsplit(basename(file), "\\.") %>% .[[1]] %>% .[[2]]
# read data
if(fileEnding == "csv"){
data = read.csv(files[[file_idx]])
}else{
data = readxl::read_xlsx(file)
}
data
data %>% glimpse
data %>%
mutate(
across(where(is.character),
~as.numeric(gsub(",", "", .x))
)
) -> data
data
# wrangle it a bit
col_indices = which(grepl("week|Russia_", names(data)))
data = data[, col_indices]
data %>% glimpse
data[["EU Ziel"]] = (1/3) * data$Russia_2021
print(head(data))
print(tail(data))
names(data)[names(data) == "Russia_avg"] = "Durchschnitt 2015 - 2022"
names(data)[names(data) == "Russia_2022"] = "2022"
datae
data
View(data)
