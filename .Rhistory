library(dplyr)
# url ---------------------------------------------------------------------
url = "https://ec.europa.eu/energy/observatory/reports/latest_prices_with_taxes.xlsx"
# download file -----------------------------------------------------------
file = paste0(tempdir(), "/", "temp.xlsx")
download.file(url, file)
data = readxl::read_xlsx(file, sheet = 2)
# get the date (in col 5 header) ------------------------------------------------------------
col5_header = names(data)[[5]]
date_unformatted = gsub(".*\\s(\\d{1,2}\\/\\d{1,2}/\\d{1,2})$", "\\1", col5_header)
date = as.Date(date_unformatted, format="%m/%d/%y")
# format data --------------------------------------------------------------
new_names = c("country", "super95", "diesel", "heizöl")
date
data = data[,1:length(new_names)]
names(data) = new_names
data = data[!is.na(data$country) & !is.na(data$diesel), ]
new_data = lapply(seq_along(data), function(i){
if(i != 1){
ret = as.numeric(gsub(",", "", data[[i]]))
}else{
ret = data[[i]]
}
ret
})
new_data = as.data.frame(new_data)
new_data = setNames(new_data, names(data))
new_data = new_data[1:27, ]
new_data[["date"]] = date
# replace Czech Rep. ------------------------------------------------------
new_data$country = ifelse(new_data$country == "Czechia", "Czech Rep.", new_data$country)
# make german names -------------------------------------------------------
res = sapply(new_data$country, function(x) {
switch(
x,
"Austria" = "Österreich",
"Belgium" = "Belgien",
"Bulgaria" = "Bulgarien",
"Croatia" = "Kroatien",
"Cyprus" = "Zypern",
"Denmark" = "Dänemark",
"Estonia" = "Estland",
"Finland" = "Finnland",
"France" = "Frankreich",
"Germany" = "Deutschland",
"Greece" = "Griechenland",
"Hungary" = "Ungarn",
"Czech Rep." = "Tschechien",
"Ireland" = "Irland",
"Italy" = "Italien",
"Latvia" = "Lettland",
"Lithuania" = "Litauen",
"Luxembourg" = "Luxemburg",
"Malta" = "Malta",
"Netherlands" = "Niederlande",
"Poland" = "Polen",
"Portugal" = "Portugal",
"Romania" = "Rumänien",
"Slovakia" = "Slowakei",
"Slovenia" = "Slowenien",
"Spain" = "Spanien",
"Sweden" = "Schweden",
)
})
new_data[["country_ger"]] = res
new_data %>%
mutate(across(where(is.numeric),
~ round(.x / 1000, 2))) -> data_per_l
# use commas instead of points --------------------------------------------
data_per_l %>%
mutate(across(where(is.double),
~ gsub("\\.", ",", .x))) %>%
mutate(
diesel_tooltip = diesel
) -> data_final
# save data ---------------------------------------------------------------
fn = here::here("R/output/weekly_fuel_prices/weeky_fuel_prices.csv")
data_final
print(paste0("Filename: ", fn))
dir = dirname(fn); if(!dir.exists(dir)) dir.create(dir, recursive = T)
print(paste0("Created: ", dir))
write.csv(data_final, fn)
library(tidyverse)
url = "https://ec.europa.eu/energy/observatory/reports/Oil_Bulletin_Prices_History.xlsx"
file = paste0(tempdir(), "/", "temp.xlsx")
download.file(url, file)
data_raw = readxl::read_xlsx(file, sheet = 8)
# vals --------------------------------------------------------------------
vals = c(
"Euro-super 95",
"Dieselkraftstoff",
"Heizöl \\(II\\)"
)
data_raw %>%
rename(country_date = 1) %>%
mutate(country = ifelse(str_detect(country_date, "^[A-Z]{2}\\b"),
country_date,
NA)) %>%
tidyr::fill(country) %>%
rename(
date = 1,
ex_rate = 2,
super_95 = 3,
diesel = 4,
heizoel = 5
)  -> data_renamed
print("date renamed")
print(head(data_renamed))
# remove empty columns ----------------------------------------------------
data_only_necessary_cols = data_renamed %>%
select(
-c(6,7,8)
)
print("data only necessary cols")
print(head(data_only_necessary_cols))
data_only_necessary_cols %>%
filter(
if_all(
everything(),
~!is.na(.x)
)
) -> data_no_na
print("data only no na")
print(head(data_no_na))
data_no_na %>%
split(.$country) %>%
lapply(function(x) {
x = x[2:nrow(x),]
# format date and numeric types
x[["date"]] = as.Date(as.numeric(x$date), origin = as.Date("1899-12-30"))
x = x %>% mutate(across(2:ncol(.),
~ gsub(",", "", .x)))
# filter only after 2020
x = x %>%
filter(
date > as.Date("2020-01-01")
)
}) %>% bind_rows() %>%
mutate(
country = recode(country,
"AT"  = "Österreich",
"BG" = "Bulgarien",
"BE"  = "Belgien",
"BU"  = "Bulgarien",
"CY"  = "Zypern",
"CZ"  = "Tschechien",
"DE"  = "Deutschland",
"DK"  = "Dänemark",
"EE"  = "Estland",
"ES"  = "Spanien",
"FI"  = "Finnland",
"FR"  = "Frankreich",
"GR"  = "Griechenland",
"HU"  = "Ungarn",
"LV"  = "Lettland",
"IT"  = "Italien",
"RO"  = "Rumänien",
"LT"  = "Lituaen",
"PT"  = "Portugal",
"HR" = "Kroatien",
"IE" = "Irland",
"LU" = "Luxemburg",
"SE"  = "Schweden",
"SI"  = "Slovenien",
"SK"  = "Slovakei",
"PL"  = "Polen",
"EE"  = "Estland",
"MT" = "Malta",
"NL" = "Niederlanden"
)
) -> one_df_all_countries
print("formatted data")
print(head(one_df_all_countries))
# only take the diesel ----------------------------------------------------
one_df_all_countries %>%
select(
1,
country,
diesel
) %>%
mutate(
diesel = as.numeric(diesel) / 1000
) %>%
pivot_wider(
names_from = country,
values_from = diesel
) -> diesel_wide
diesel_wide
path_diesel = here::here("R/output/weekly_fuel_prices/historic/historic_diesel.csv")
dir = dirname(path_diesel); if(!dir.exists(dir)) dir.create(dir, recursive = T)
write.csv(diesel_wide, path_diesel)
library(httr)
# 2.12
url = "https://www.bruegel.org/sites/default/files/2022-11/Gas%20tracker%2029.11.22.zip"
# download zip ------------------------------------------------------------
download_path = tempfile()
download_dir = dirname(download_path)
# Download the data in loop -----------------------------------------------
success = FALSE
i = 1
while(!success & i <= 5) {
print(paste0("Try for the ", i, ". time"))
# try the download
res = httr::GET(url, write_disk(download_path, overwrite = T))
print(paste0("res: ", res$status_code))
# if it did work
if (res$status_code == 200) {
success = TRUE
}
# if it did not work
i = i + 1
}
if(!res$status_code == 200) stop("Download did not work after 5 tries")
unzip(download_path, exdir = download_dir)
# the unzipped file does not contain the files, but another directory which apparently
# changes each week its name. But every week so far the word "Gas" was in it
unzipped_dir_name = dir(download_dir, ".*[gG]as.*", full.names = T)
# find file
files = dir(unzipped_dir_name, "*.csv|xlsx", full.names = T)
print(paste0("files: ", files))
file_idx = which(grepl("country_data", files))
# read data
data = read.csv(files[[file_idx]])
# wrangle it a bit
col_indices = which(grepl("week|Russia_", names(data)))
data = data[, col_indices]
data[["EU Ziel"]] = (1/3) * data$Russia_2021
print(head(data))
print(tail(data))
names(data)[names(data) == "Russia_avg"] = "Durchschnitt 2015 - 2022"
data
# remove comma ------------------------------------------------------------
data %>%
mutate(
across(where(is.numeric),
~as.numeric(gsub(",", "", .x))
)
)
data
# remove comma ------------------------------------------------------------
data %>%
mutate(
across(where(is.numeric),
~as.numeric(gsub(",", "", .x))
)
)
data %>% glimpse
# remove comma ------------------------------------------------------------
data %>%
mutate(
across(where(is.charcter),
~as.numeric(gsub(",", "", .x))
)
)
# remove comma ------------------------------------------------------------
data %>%
mutate(
across(where(is.character),
~as.numeric(gsub(",", "", .x))
)
)
# remove comma ------------------------------------------------------------
data %>%
mutate(
across(where(is.character),
~as.numeric(gsub(",", "", .x))
)
) -> data
output_file = "R/output/natural_gas_russia_europe.csv"
dir = dirname(output_file); if(!dir.exists(dir)) dir.create(dir, recursive = T)
write.csv(data, output_file)
library(httr)
# 2.12
url = "https://www.bruegel.org/sites/default/files/2022-11/Gas%20tracker%2029.11.22.zip"
# 9.12
url = "https://www.bruegel.org/sites/default/files/2022-12/Gas%20tracker%2007.12.22.zip"
# download zip ------------------------------------------------------------
download_path = tempfile()
download_dir = dirname(download_path)
# Download the data in loop -----------------------------------------------
success = FALSE
i = 1
while(!success & i <= 5) {
print(paste0("Try for the ", i, ". time"))
# try the download
res = httr::GET(url, write_disk(download_path, overwrite = T))
print(paste0("res: ", res$status_code))
# if it did work
if (res$status_code == 200) {
success = TRUE
}
# if it did not work
i = i + 1
}
if(!res$status_code == 200) stop("Download did not work after 5 tries")
unzip(download_path, exdir = download_dir)
# the unzipped file does not contain the files, but another directory which apparently
# changes each week its name. But every week so far the word "Gas" was in it
unzipped_dir_name = dir(download_dir, ".*[gG]as.*", full.names = T)
# find file
files = dir(unzipped_dir_name, "*.csv|xlsx", full.names = T)
print(paste0("files: ", files))
file_idx = which(grepl("country_data", files))
# read data
data = read.csv(files[[file_idx]])
# wrangle it a bit
col_indices = which(grepl("week|Russia_", names(data)))
data = data[, col_indices]
data[["EU Ziel"]] = (1/3) * data$Russia_2021
print(head(data))
print(tail(data))
names(data)[names(data) == "Russia_avg"] = "Durchschnitt 2015 - 2022"
names(data)[names(data) == "Russia_2022"] = "2022"
# remove comma ------------------------------------------------------------
data %>%
mutate(
across(where(is.character),
~as.numeric(gsub(",", "", .x))
)
) -> data
library(tidyverse)
# remove comma ------------------------------------------------------------
data %>%
mutate(
across(where(is.character),
~as.numeric(gsub(",", "", .x))
)
) -> data
output_file = "R/output/natural_gas_russia_europe.csv"
dir = dirname(output_file); if(!dir.exists(dir)) dir.create(dir, recursive = T)
write.csv(data, output_file)
install.packages("rlist")
library(rlist)
devs <-
list(
p1=list(name="Ken",age=24,
interest=c("reading","music","movies"),
lang=list(r=2,csharp=4)),
p2=list(name="James",age=25,
interest=c("sports","music"),
lang=list(r=3,java=2,cpp=5)),
p3=list(name="Penny",age=24,
interest=c("movies","reading"),
lang=list(r=1,cpp=4,python=2)))
devs
str(devs)
glimpse(devs)
library(tidyverse)
glimpse(devs)
library(rlist)
rlist::list.filter(devs, "music" %in% interest)
install.packages("terse")
devtools::install_github("coolbutuseless/terse")
library(rvest)
html = rvest::read_html("https://www.bruegel.org/dataset/european-natural-gas-imports")
html
html %>%
html_elements('a[title="Download data"]')
html %>%
html_elements('a[title="Download data"]') %>%
html_attr("href")
library(rvest)
# find the link
html_attribute("href", html_elements(html, 'a[title="Download data"]'))
# find the link
html_attr("href", html_elements(html, 'a[title="Download data"]'))
html_elements(html, 'a[title="Download data"]')
?html_attr
# find the link
html_attr(html_elements(html, 'a[title="Download data"]'), "href")
# find the link
path = html_attr(html_elements(html, 'a[title="Download data"]'), "href")
paste0("https://www.bruegel.org/", path)
# read the html
html = rvest::read_html("https://www.bruegel.org/dataset/european-natural-gas-imports")
# find the link
path = html_attr(html_elements(html, 'a[title="Download data"]'), "href")
url = paste0("https://www.bruegel.org/", path)
url
# download zip ------------------------------------------------------------
download_path = tempfile()
download_dir = dirname(download_path)
# Download the data in loop -----------------------------------------------
success = FALSE
i = 1
while(!success & i <= 5) {
print(paste0("Try for the ", i, ". time"))
# try the download
res = httr::GET(url, write_disk(download_path, overwrite = T))
print(paste0("res: ", res$status_code))
# if it did work
if (res$status_code == 200) {
success = TRUE
}
# if it did not work
i = i + 1
}
library(httr)
library(rvest)
# Download the data in loop -----------------------------------------------
success = FALSE
i = 1
while(!success & i <= 5) {
print(paste0("Try for the ", i, ". time"))
# try the download
res = httr::GET(url, write_disk(download_path, overwrite = T))
print(paste0("res: ", res$status_code))
# if it did work
if (res$status_code == 200) {
success = TRUE
}
# if it did not work
i = i + 1
}
if(!res$status_code == 200) stop("Download did not work after 5 tries")
unzip(download_path, exdir = download_dir)
# the unzipped file does not contain the files, but another directory which apparently
# changes each week its name. But every week so far the word "Gas" was in it
unzipped_dir_name = dir(download_dir, ".*[gG]as.*", full.names = T)
# find file
files = dir(unzipped_dir_name, "*.csv|xlsx", full.names = T)
print(paste0("files: ", files))
file_idx = which(grepl("country_data", files))
# read data
data = read.csv(files[[file_idx]])
# wrangle it a bit
col_indices = which(grepl("week|Russia_", names(data)))
data = data[, col_indices]
data[["EU Ziel"]] = (1/3) * data$Russia_2021
# find file
files = dir(unzipped_dir_name, "*.csv|xlsx", full.names = T)
print(paste0("files: ", files))
file_idx = which(grepl("country_data", files))
# read data
data = read.csv(files[[file_idx]])
data
View(data)
# wrangle it a bit
col_indices = which(grepl("week|Russia_", names(data)))
data = data[, col_indices]
data[["EU Ziel"]] = (1/3) * data$Russia_2021
data$Russia_2021 * 1/3
data$Russia_2021
data %>% glimpse
str(data)
# format as numeric
lapply(data, as.numeric)
# 15.12
url = "https://www.bruegel.org/sites/default/files/2022-12/Gas%20tracker%2013.12.22.zip"
# download zip ------------------------------------------------------------
download_path = tempfile()
download_dir = dirname(download_path)
# Download the data in loop -----------------------------------------------
success = FALSE
i = 1
while(!success & i <= 5) {
print(paste0("Try for the ", i, ". time"))
# try the download
res = httr::GET(url, write_disk(download_path, overwrite = T))
print(paste0("res: ", res$status_code))
# if it did work
if (res$status_code == 200) {
success = TRUE
}
# if it did not work
i = i + 1
}
if(!res$status_code == 200) stop("Download did not work after 5 tries")
unzip(download_path, exdir = download_dir)
# the unzipped file does not contain the files, but another directory which apparently
# changes each week its name. But every week so far the word "Gas" was in it
unzipped_dir_name = dir(download_dir, ".*[gG]as.*", full.names = T)
# find file
files = dir(unzipped_dir_name, "*.csv|xlsx", full.names = T)
print(paste0("files: ", files))
file_idx = which(grepl("country_data", files))
# read data
data = read.csv(files[[file_idx]])
data
str(data)
data
str(data)
library(dplyr)
data %>%
mutate(
across(where(is.character),
~as.numeric(gsub(",", "", .x))
)
) -> data
data
data %>% glimpse()
# wrangle it a bit
col_indices = which(grepl("week|Russia_", names(data)))
data = data[, col_indices]
daa
data
data[["EU Ziel"]] = (1/3) * data$Russia_2021
View(data)
library(rvest)
library(dplyr)
# url ---------------------------------------------------------------------
url = "https://www.bruegel.org/dataset/european-natural-gas-demand-tracker"
# get the table -----------------------------------------------------------
rvest::read_html(url) %>%
html_elements("table")
# url ---------------------------------------------------------------------
url = "https://www.bruegel.org/dataset/european-natural-gas-demand-tracker"
# get the table -----------------------------------------------------------
rvest::read_html(url) %>%
html_elements("table")
# get the table -----------------------------------------------------------
rvest::read_html(url)
