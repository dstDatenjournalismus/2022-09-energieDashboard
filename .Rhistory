library(readxl)
library(here)
library(tidyverse)
library(httr2)
url = "https://ec.europa.eu/energy/observatory/reports/latest_prices_with_taxes.xlsx"
file = paste0(tempdir(), "/", "temp.xlsx")
download.file(url, file)
data = readxl::read_xlsx(file, sheet = 2)
# get the date (in col 5 header) ------------------------------------------------------------
col5_header = names(data)[[5]]
date_unformatted = gsub(".*(\\d{1,2}/\\d{1,2}/\\d{1,2})$", "\\1", col5_header)
date = as.Date(date_unformatted, format="%m/%d/%y")
# format data --------------------------------------------------------------
new_names = c("country", "super95", "diesel", "heizöl")
data = data[,1:length(new_names)]
names(data) = new_names
data
data = data[!is.na(data$country) & !is.na(data$diesel), ]
new_data = lapply(seq_along(data), function(i){
if(i != 1){
ret = as.numeric(gsub(",", "", data[[i]]))
}else{
ret = data[[i]]
}
ret
})
new_data = as.data.frame(new_data)
new_data = setNames(new_data, names(data))
new_data = new_data[1:27, ]
new_data[["date"]] = date
# replace Czech Rep. ------------------------------------------------------
new_data$country = ifelse(new_data$country == "Czechia", "Czech Rep.", new_data$country)
# make german names -------------------------------------------------------
res = sapply(new_data$country, function(x) {
switch(
x,
"Austria" = "Österreich",
"Belgium" = "Belgien",
"Bulgaria" = "Bulgarien",
"Croatia" = "Kroatien",
"Cyprus" = "Zypern",
"Denmark" = "Dänemark",
"Estonia" = "Estland",
"Finland" = "Finnland",
"France" = "Frankreich",
"Germany" = "Deutschland",
"Greece" = "Griechenland",
"Hungary" = "Ungarn",
"Czech Rep." = "Tschechien",
"Ireland" = "Irland",
"Italy" = "Italien",
"Latvia" = "Lettland",
"Lithuania" = "Litauen",
"Luxembourg" = "Luxemburg",
"Malta" = "Malta",
"Netherlands" = "Niederlanden",
"Poland" = "Polen",
"Portugal" = "Portugal",
"Romania" = "Rumänien",
"Slovakia" = "Slovakei",
"Slovenia" = "Slowenien",
"Spain" = "Spanien",
"Sweden" = "Schweden",
)
})
new_data[["country_ger"]] = res
# save data ---------------------------------------------------------------
fn = sprintf(here("R/output/weekly_fuel_prices/weeky_fuel_prices.csv"))
fn
path_diesel = here("output/weekly_fuel_prices/historic/historic_diesel.csv")
path_diesel
# save data ---------------------------------------------------------------
fn = here::here("R/output/weekly_fuel_prices/weeky_fuel_prices.csv")
fn
print(paste0("Created: ", fn))
library(RCurl)
# url ---------------------------------------------------------------------
url = "https://www.bruegel.org/sites/default/files/2022-09/gas_tracker_update_.zip"
a = getURL(url)
a
?download.file
library(tidyverse)
library(glue)
library(readxl)
library(here)
# url ---------------------------------------------------------------------
url = "https://www.bruegel.org/sites/default/files/2022-09/gas_tracker_update_.zip"
# download zip ------------------------------------------------------------
download_path = tempfile()
download_dir = dirname(download_path)
download.file(url, download_path, method="libcurl", headers = c("User-Agent" = "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:104.0) Gecko/20100101 Firefox/104.0"))
?httr2::req_perform()
url
request(url) %>% req_perform()
a = request(url) %>% req_perform()
a
httr::GET(url, write_disk)
library(httr)
httr::GET(url, write_disk(download_path))
# download.file(url, download_path, method="libcurl", headers = c("User-Agent" = "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:104.0) Gecko/20100101 Firefox/104.0"))
httr::GET(url, write_disk(download_path, overwrite = T))
unzip(download_path, exdir = download_dir)
files = dir(download_dir)
files
library(httr)
# url ---------------------------------------------------------------------
url = "https://www.bruegel.org/sites/default/files/2022-09/gas_tracker_update_.zip"
# download zip ------------------------------------------------------------
download_path = tempfile()
download_dir = dirname(download_path)
# download.file(url, download_path, method="libcurl", headers = c("User-Agent" = "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:104.0) Gecko/20100101 Firefox/104.0"))
httr::GET(url, write_disk(download_path, overwrite = T))
unzip(download_path, exdir = download_dir)
files = dir(download_dir)
print(files)
# find file
files = dir(download_dir, "*.csv|xlsx")
file_idx = which(grepl("country_data", files))
# read data
data = read.csv(files[[file_idx]])
file_idx = which(grepl("country_data", files))
file_idx
files[[file_idx]]
# find file
files = dir(download_dir, "*.csv|xlsx", full.names = T)
file_idx = which(grepl("country_data", files))
# read data
data = read.csv(files[[file_idx]])
head(data)
# wrangle it a bit
grepl("week|Russia_", names(data))
# wrangle it a bit
col_indices = grepl("week|Russia_", names(data))
# wrangle it a bit
col_indices = which(grepl("week|Russia_", names(data)))
col_indices
data = data[col_indices, ]
head(data)
data = data[, col_indices]
head(data)
data = complete.cases(data)
data
data = data[complete.cases(data), ]
# wrangle it a bit
col_indices = which(grepl("week|Russia_", names(data)))
# read data
data = read.csv(files[[file_idx]])
# wrangle it a bit
col_indices = which(grepl("week|Russia_", names(data)))
data = data[, col_indices]
data = data[complete.cases(data), ]
head(data)
data[["EU Ziel"]] = (1/3) * data$Russia_2021
names(date)
names(data)
names(data)[names(data) == "Russia_avg" = "Durchschnitt 2015 - 2022"
names(data)[names(data) == "Russia_avg"] = "Durchschnitt 2015 - 2022"
names(date)
names(data)
names(data)[names(data) == "Russia_2022"] = "2022"
names(data)
library(httr)
# url ---------------------------------------------------------------------
url = "https://www.bruegel.org/sites/default/files/2022-09/gas_tracker_update_.zip"
# download zip ------------------------------------------------------------
download_path = tempfile()
download_dir = dirname(download_path)
# download.file(url, download_path, method="libcurl", headers = c("User-Agent" = "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:104.0) Gecko/20100101 Firefox/104.0"))
httr::GET(url, write_disk(download_path, overwrite = T))
unzip(download_path, exdir = download_dir)
files = dir(download_dir)
print(files)
# find file
files = dir(download_dir, "*.csv|xlsx", full.names = T)
file_idx = which(grepl("country_data", files))
# read data
data = read.csv(files[[file_idx]])
# wrangle it a bit
col_indices = which(grepl("week|Russia_", names(data)))
data = data[, col_indices]
data = data[complete.cases(data), ]
data[["EU Ziel"]] = (1/3) * data$Russia_2021
names(data)[names(data) == "Russia_avg"] = "Durchschnitt 2015 - 2022"
names(data)[names(data) == "Russia_2022"] = "2022"
output_file = "R/output/natural_gas_russia_europe.csv"
dir = dirname(output_file); if(!dir.exists(dir)) dir.create(dir, recursive = T)
data
output_file
library(httr)
today = as.Date(Sys.time())
tomorrow = today + 1
# url ---------------------------------------------------------------------
url = sprintf("https://transparency.apg.at/transparency-api/api/v1/Data/AGPT/German/M15/%sT000000/%sT000000", today, tomorrow)
# download zip ------------------------------------------------------------
download_path = tempfile()
download_dir = dirname(download_path)
# download data -----------------------------------------------------------
# download.file(url, download_path, method="libcurl", headers = c("User-Agent" = "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:104.0) Gecko/20100101 Firefox/104.0"))
httr::GET(url, write_disk(download_path, overwrite = T))
library(jsonlite)
content = fromJSON(download_path)
content
library(httr)
library(jsonlite)
today = as.Date(Sys.time())
tomorrow = today + 1
# url ---------------------------------------------------------------------
url = sprintf("https://transparency.apg.at/transparency-api/api/v1/Data/AGPT/German/M15/%sT000000/%sT000000", today, tomorrow)
url = "https://transparency.apg.at/transparency-api/api/v1/Download/AGPT/German/M15/2021-01-01T000000/2022-09-26T000000/AGPT_2020-12-31T23_00_00Z_2022-09-26T22_00_00Z_60M_de_2022-09-26T15_40_08Z.csv"
# download zip ------------------------------------------------------------
download_path = tempfile()
download_dir = dirname(download_path)
# download data -----------------------------------------------------------
# download.file(url, download_path, method="libcurl", headers = c("User-Agent" = "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:104.0) Gecko/20100101 Firefox/104.0"))
httr::GET(url, write_disk(download_path, overwrite = T))
d = read.csv(download_path)
url = "https://transparency.apg.at/transparency-api/api/v1/Download/AGPT/German/M15/2021-01-01T000000/2022-09-26T000000/AGPT_2020-12-31T23_00_00Z_2022-09-26T22_00_00Z_60M_de_2022-09-26T15_40_08Z.csv"
# download data -----------------------------------------------------------
download.file(url, download_path, method="libcurl", headers = c("User-Agent" = "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:104.0) Gecko/20100101 Firefox/104.0"))
d = read.csv(download_path)
head(d)
d
d = read.csv(download_path)
dir(download_dir)
download_path
d = read_csv(download_path)
head(d)
d = read.delim(download_path, sep = ";")
head(d)
View(new_data)
